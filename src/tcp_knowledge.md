# TCP知识记录以及面试相关

> with Gemini

## 认识TCP和UDP

### OSI模型和TCP/IP协议簇

**OSI模型**(*Open Systems Interconnection Model*)是一个概念性的框架，由国际标准化组织(ISO)于1980年代提出，旨在定义**不同计算机系统互联的标准**。它将复杂的**网络通信过程**划分为七个抽象的、逻辑上独立的层，每层都有特定的功能。这七层从上到下分别是

1. **应用层**(*Application Layer*)：最靠近用户的一层，为应用程序提供网络服务。例如HTTP、FTP、SMTP等协议就在这一层
2. **表示层** (*Presentation Layer*)： 负责**数据格式的转换**、数据加密和解密、数据压缩和解压。确保不同系统间的数据表示方式兼容
3. **会话层** (*Session Layer*)： 负责建立、管理和终止应用程序之间的会话连接。它提供对话控制和同步。
4. **传输层** (*Transport Layer*)： 提供**端到端（进程到进程）**的数据传输服务，负责数据的分段、重组、错误检查和流量控制。TCP和UDP就属于这一层
5. **网络层** (*Network Layer*)： 负责数据包的**路由和寻址**，将数据从源主机传输到目标主机。IP协议就在这一层
6. **数据链路层** (*Data Link Layer*)： 负责在网络的物理链路上无差错地传输数据帧，处理物理地址（MAC地址）、错误检测和流量控制
7. **物理层** (*Physical Layer*)： 最底层，负责传输比特流，定义了物理介质（如电缆、光纤）、传输速率、电压等**物理特性**

实际的互联网并没有完全按照OSI的七层结构来实现。**TCP/IP协议簇** 是互联网的实际标准，它是一个更加简洁的**四层或五层模型**，其功能与OSI模型是对应的。以下是TCP/IP协议簇的四层模型以及它们与OSI模型的对应关系

1. **应用层** (*Application Layer*)
   1. 对应OSI模型的应用层、表示层和会话层
   2. 包含所有应用层协议，如HTTP、FTP、SMTP、DNS等
2. **传输层** (*Transport Layer*)
   1. 对应 OSI 模型的**传输层**，负责端到端的数据传输
   2. 主要协议是**TCP**(*Transmission Control Protocol*)和**UDP**(*User Datagram Protocol*)
3. **网络层** (*Internet Layer*)
   1. 对应OSI模型的网络层，负责数据包的路由和跨网络的寻址
   2. 核心协议是**IP**(*Internet Protocol*)
4. **网络接口层** (*Network Interface Layer*)/**数据链路层** (*Data Link Layer*)
   1. 对应 OSI 模型的**数据链路层和物理层**。处理网络硬件和物理传输细节，如 Ethernet、Wi-Fi 等协议。

TCP/IP协议簇的各层之间遵循严格的**协议栈**关系

* **封装** (*Encapsulation*)：数据从应用层向下传递时，每一层都会给数据添加一个自己的**协议头** (*Header*)或**协议尾**（*Trailer*）。这个过程就像套娃一样，每一层都把自己所需的信息“封装”在数据外面。例如，TCP层会添加TCP头，IP层会添加IP头
* **解封装** (*Decapsulation*)：封装的反过程，数据从物理层向上传递时，每一层会剥离（解析）自己对应的协议头/尾，并将内部数据传递给上一层，直到最终到达应用层
* **层次独立性**：每层只关心自己的功能，并且只与紧邻的上下层进行交互。例如，传输层不需要知道数据链路层如何将比特流转换成电信号，它只需要将处理好的数据交给网络层即可
* 服务提供者与服务使用者：**下一层为上一层提供服务**。例如，网络层为传输层提供数据包的路由服务，传输层不需要关心路由的具体实现

#### 为什么分层思想很重要？

分层思想是网络协议设计的核心，其重要性体现在以下几个方面：

1. 降低复杂性（分治）：将复杂的网络通信问题分解成若干个更小的、更易于管理和理解的子问题。每层只关注一个特定功能，使得设计、实现和调试变得简单
2. 模块化和独立性：每层都是一个独立的模块，**修改某一层的功能不会影响其他层的设计**。例如，可以更换底层的数据链路技术（如从以太网切换到Wi-Fi），而上层的应用协议（如HTTP）无需改变。
3. 促进标准化：分层为不同厂商开发和实现网络产品提供了**统一的接口和规范**。只要遵循同一层协议的约定，不同厂商的设备就可以互相通信。这正是互联网能够全球互联的基础
4. 易于维护和升级：当需要对网络协议进行升级或修复漏洞时，通常只需要修改或替换受影响的层，而不需要重新设计整个系统
5. 灵活性：允许在不影响其他层的情况下替换或添加新的协议。例如，可以在传输层选择使用TCP（可靠传输）或UDP（不可靠传输），以适应不同的应用需求

理解分层思想，就像理解软件工程中的模块化设计一样，它是构建大型、复杂、可维护系统的基本原则。分层设计的指导思想是分治，把网络通信的大问题分解为更小的、可解的问题，这里就降低了问题的复杂性。解决各个小问题（对应各个层，这是适合网络通信问题的划分方式，因为这套模型的扩展是靠对消息的多层封装）更适合使用模块化的设计，耦合度更低，而模块化会更容易将对外交互接口定义清楚，这也促进了各层规范标准化的需求，并且模块化之后，整套系统更易于维护和升级，因为各层之间相互独立，所以维护和升级不会涉及整个系统的更新，而这些因素都构成了整套模型的**灵活性**

### TCP/UDP/QUIC的核心特性

#### TCP

TCP 是一种**面向连接的、可靠的、基于字节流的传输层协议**。它的设计目标是在不可靠的IP网络上提供可靠的数据传输服务

TCP协议的特性

1. **面向连接**(*Connection-Oriented*)
   1. 在数据传输之前，发送方和接收方必须先通过**三次握手**建立连接
   2. 数据传输完成后，需要通过**四次挥手**释放连接
   3. 连接的建立和释放都需要消耗时间和资源，一旦建立连接（高成本），后续的数据传输效率较高
2. **可靠传输**(*Reliable Transmission*）
   1. 确保数据能够**无差错、不丢失、不重复、按顺序**地从发送端传输到接收端
   2. 实现可靠性的主要机制包括
      1. **序列号**(*Sequence Number*)和**确认应答**(*Acknowledgment Number*)，保证数据按序到达和不重复
      2. **超时重传**(*Retransmission Timeout - RTO*)，发现丢包后进行重传
      3. **校验和**(*Checksum*)，检测数据在传输过程中是否损坏
      4. **肯定确认**(*Positive Acknowledgment*)，接收方收到数据后必须发送确认
3. **面向字节流**(*Byte Stream-Oriented*)
   1. TCP不关心应用层数据的具体边界，它将应用层提交的数据视为一串**无结构的字节流**
   2. TCP会根据自身的需求（如MSS，最大报文段长度）将字节流分割成**报文段**(*Segment*)进行传输
   3. 这就导致了**粘包/拆包问题**，需要应用层自行处理消息边界
4. **全双工**(*Full-Duplex*)
   1. TCP连接允许数据在**两个方向上同时传输**，互不干扰
   2. 这也是四次挥手的原因之一，因为每个方向的传输都需要独立关闭
5. **流量控制**(*Flow Control*)
   1. TCP通过**滑动窗口机制**实现流量控制
   2. 接收方通过在ACK报文中告知发送方其当前的**接收窗口**(*Advertised Window*)大小，来限制发送方的发送速率。目的是防止发送方发送数据过快，导致接收方缓冲区溢出，从而造成数据丢失
6. **拥塞控制**(*Congestion Control*)
   1. TCP 通过一系列算法（慢启动、拥塞避免、快速重传、快速恢复）来动态调整发送速率，以适应网络的负载能力。目的是防止网络过载（拥塞），从而避免大量丢包和性能下降
   2. 关注的是整个网络的状况，而不是单一接收方的处理能力

#### UDP

UDP是一种**无连接的、不可靠的、基于数据报的传输层协议**（相对于TCP记忆）。它提供的是**尽力而为**(*best-effort*) 的传输服务。

UDP协议的特性

1. **无连接**(*Connectionless*)
   1. 在数据传输之前无需建立连接。发送方可以直接向接收方发送数据报
   2. 传输完成后，也无需释放连接
   3. 优点：开销小，传输速度快，适用于*对延迟敏感的应用*
2. **不可靠传输**(*Unreliable Transmission*)
   1. UDP不保证数据报的完整性、不丢失、不重复、按顺序
   2. 如果数据报在传输过程中丢失、乱序或损坏，UDP**不会进行重传或通知上层应用**
   3. 错误检测仅限于可选的**校验和**（如果启用）
3. **基于数据报**(*Datagram-Oriented*)
   1. UDP传输的基本单位是**数据报**(*Datagram*)
   2. 每个数据报都是一个独立的、带有完整头部信息的报文（有格式），包含**源端口和目的端口**
   3. UDP会保留应用层消息的边界，即发送方发送一个数据报，接收方就接收一个完整的数据报，**没有粘包/拆包问题**
4. **无流量控制**(*No Flow Control*)
   1. UDP不提供流量控制机制。发送方可以以任意速率发送数据，不考虑接收方的处理能力
   2. 优点：简单高效。缺点：可能导致接收方缓冲区溢出而丢包
5. **无拥塞控制**(*No Congestion Control*)
   1. UDP不提供拥塞控制机制。发送方不关心网络是否拥塞，会持续发送数据
   2. 优点：在某些场景下（如实时音视频，允许少量丢包以保证流畅性）可以获得更低的延迟。缺点：可能加剧网络拥塞
6. **头部开销小**(*Small Header Overhead*)
   1. UDP报文头部固定为8字节（源端口、目的端口、长度、校验和）
   2. 对比：TCP报文头部至少20字节。UDP的头部开销远小于TCP，因此在传输小数据量时效率更高

---

#### TCP vs UDP

| 特性       | TCP                                    | UDP                                          |
| :--------- | :--------------------------------------------------------------------- | :-------------------------------------------------------------------- |
| **连接性** | 面向连接（三次握手，四次挥手）                                         | 无连接                                                                |
| **可靠性** | 可靠传输（保证数据完整、不丢、不重、按序）                                   | 不可靠传输（尽力而为）                                                |
| **传输方式** | 字节流                                                  | 数据报                                                     |
| **消息边界** | 无（存在粘包/拆包问题）                                                | 有（保留消息边界）                                                    |
| **拥塞控制** | 有                                                                     | 无                                                                    |
| **流量控制** | 有                                                                     | 无                                                                    |
| **头部开销** | 至少20字节                                                           | 固定8字节                                                           |
| **传输速度** | 相对较慢（因控制机制复杂）                                             | 相对较快（开销小，无复杂控制）                                        |
| **适用场景** | 对数据完整性、可靠性要求高的应用（HTTP, FTP, Email, SSH, 数据库）      | 对实时性要求高，允许少量丢包的应用（DNS, DHCP, VoIP, 实时音视频, 游戏） |

#### QUIC

QUIC(Quick UDP Internet Connections)是Google开发的一种**基于UDP的多路复用传输协议**，旨在解决TCP在现代互联网应用中遇到的一些**性能瓶颈**，特别是在其与HTTP/2结合使用时。它被设计为下一代HTTP(HTTP/3)的底层传输协议

QUIC出现的原因(TCP的痛点)

1. **队头阻塞**(*Head-of-Line Blocking*)问题：TCP在一个连接上，即使使用了多路复用（如 HTTP/2），如果一个数据包丢失，整个连接上的所有后续数据包（即使它们属于不同的请求/响应流）都必须等待丢失的包被重传和确认，才能继续处理。这会严重影响并发性能
2. **连接建立延迟**：TCP的三次握手需要1个**RTT**(*Round Trip Time*)延迟。如果加上TLS加密握手，通常需要2-3个 RTT才能开始传输应用数据。
3. **连接迁移困难**：TCP连接由四元组（源IP、源端口、目的IP、目的端口）唯一标识。当用户设备在不同网络（如从 Wi-Fi切换到蜂窝网络）之间切换时，IP地址会改变，导致TCP连接断开，需要重新建立
4. **内核实现和升级困难**：TCP协议栈通常实现在操作系统内核中，其更新和部署非常缓慢，难以快速迭代和优化

QUIC协议的核心特性

1. 基于UDP实现
   1. QUIC运行在UDP之上，绕过了操作系统内核中TCP协议栈的限制，使得协议的迭代和部署更加灵活和快速
   2. 利用UDP的无连接特性，减少了连接建立的开销
2. 更快的连接建立
   1. QUIC可以在0-RTT或1-RTT内完成连接建立和加密握手，大大减少了延迟
   2. 0-RTT意味着如果客户端之前连接过服务器，并在本地缓存了会话信息，可以直接发送应用数据，无需任何额外握手
3. 解决队头阻塞问题
   1. QUIC在单个连接上实现了**多路复用 (Multiplexing)**
   2. 每个逻辑流都是独立的，即使一个流中的数据包丢失，也只会影响该流，而不会阻塞其他流的数据传输
4. 连接迁移 (Connection Migration)
   1. QUIC连接通过一个**Connection ID**来标识，而不是传统的四元组
   2. 当客户端的IP地址或端口发生变化时，只要Connection ID不变，连接就可以继续保持，而无需重新建立。这对于移动设备尤其重要
5. 内置TLS 1.3加密
   1. QUIC将TLS 1.3集成到协议握手过程中，所有数据默认加密，提供了更好的安全性
   2. 加密握手与传输握手合并，进一步降低了延迟
6. 前向纠错(Forward Error Correction, FEC) (可选)
   1. QUIC可以选择性地使用FEC，通过发送冗余数据来恢复部分丢失的数据包，减少重传的需要，在高丢包率网络中表现更好
7. 更灵活的拥塞控制
   1. 由于在用户空间实现，QUIC可以更灵活地集成和测试新的拥塞控制算法（如BBR），并根据应用需求进行定制

* QUIC已经成为**HTTP/3**的底层传输协议
* 它是未来互联网传输协议发展的一个重要方向

### 端口号的作用

端口号是传输层的一个核心概念。假设你家里的地址是IP地址，邮件会投递到你家。但是如果你家里有很多人（比如你的父母、兄弟姐妹和你），寄给你的信怎么才能准确送到你手里，而不是你爸妈手里呢？这就需要一个**房间号**或者**姓名**来区分

在网络中，IP地址负责定位一台主机（计算机），而**端口号**(*Port Number*)则负责定位一台主机上运行的特定应用程序或服务进程。它的作用主要体现在以下几个方面

1. **区分不同的应用进程**(*Process Identification*)：当数据包到达一台主机时，主机需要知道这个数据是发送给哪个应用程序的。端口号就是用来做这个区分的。例如，Web服务器通常监听80端口（HTTP）或443端口（HTTPS），邮件服务器监听25端口（SMTP），而你的聊天程序可能会使用一个随机的高位端口。客户端发送请求时，会指定目的IP地址和目的端口号，这样**服务器就能将请求路由到正确的服务进程**。同样，服务器响应时，会使用客户端的源端口号作为目的端口号，将响应发送回客户端的正确进程
2. **多路复用**(*Multiplexing*) 与**解多路复用**(*Demultiplexing*)
   1. 多路复用：在发送端，多个应用进程（不同的端口号）可以将数据通过同一个传输层协议（TCP或UDP）发送出去，共用一个IP地址。传输层会将不同应用的数据“打包”起来，加上各自的端口号信息交给网络层
   2. 解多路复用：在接收端，传输层收到数据后，会根据数据包中的目的端口号，将数据准确地分发给等待这个数据包的相应应用进程。这是端口号最核心的功能之一
3. **标识通信的端点**(*Endpoint Identification*)：在TCP/IP协议栈中，一个完整的通信会话由一个**套接字**(*Socket*) 来标识。一个套接字通常由(IP地址:端口号)组成。例如，一个TCP连接由四元组(源IP地址:源端口号, 目的IP地址:目的端口号)唯一标识。

#### 端口号的分类

端口号是一个**16位的无符号整数**，范围从0到65535，通常分为三类：

* **熟知端口**(*Well-Known Ports*)：0~1023，它们是为一些最常用的网络服务（如HTTP、FTP、DNS、SMTP等）预先定义和保留的。这些端口号是全球统一的，由IANA(Internet Assigned Numbers Authority)管理
  * 20/21：FTP
  * 22：SSH
  * 23：Telnet
  * 25：SMTP
  * 53：DNS
  * 80：HTTP
  * 110：POP3
  * 143：IMAP
  * 443：HTTPS
* **注册端口**(*Registered Ports*)：1024~49151，它们可以分配给用户进程或应用程序，但通常不被系统进程使用。这些端口号也可以被注册给特定的应用使用，但不如熟知端口那么严格。许多常用的应用程序会选择使用这个范围内的端口
* **动态/私有端口**(*Dynamic/Private Ports*)：49152~65535。它们是为客户端应用程序**动态分配**的端口号。当客户端程序发起连接时，通常会从这个范围中随机选择一个未被占用的端口作为源端口。服务器端一般也会从这个范围中选择端口作为其临时服务端口，尤其是在响应客户端请求时

## 连接管理

### TCP的连接管理

#### 三次握手（*Three-way Handshake*）

TCP 的三次握手是指在客户端和服务器之间建立一个TCP连接时，需要交换**三个数据包**。这个过程确保了通信双方都能正常发送和接收数据。

##### 详细过程：`SYN`、`SYN-ACK`、`ACK`的报文交换顺序和状态变迁

下面是三次握手的时序图

```mermaid
sequenceDiagram
    participant Client
    participant Server

    Note over Client,Server: 初始状态
    Client-->>Client: 处于 CLOSED 状态
    Server-->>Server: 处于 LISTEN 状态

    Client->>Server: SYN (seq=ISN_c,SYN=1,ACK=0)
    Note left of Client: 客户端发送 SYN 包<br/>状态变为 SYN_SENT

    Server->>Client: SYN-ACK (seq=ISN_s,ack=ISN_c+1,SYN=1,ACK=1)
    Note right of Server: 服务器收到 SYN，发送 SYN-ACK<br/>状态变为 SYN_RCVD

    Client->>Server: ACK (seq=ISN_c+1,ack=ISN_s+1,ACK=1)
    Note left of Client: 客户端收到 SYN-ACK，发送 ACK<br/>状态变为 ESTABLISHED

    Server-->>Server: 收到 ACK 包<br/>状态变为 ESTABLISHED
    Note over Client,Server: 连接建立成功，可以开始数据传输
```

首先定义术语

* 客户端：发起连接请求的一方
* 服务器：接收连接请求并等待连接的一方

两端的初始状态

* 客户端：处于 `CLOSED` 状态
* 服务器：处于 `LISTEN` (监听) 状态，等待客户端的连接请求

握手步骤

1. 第一次握手：客户端发送`SYN`包(*SYN - Synchronize Sequence Numbers*)
    * 动作：客户端想要建立连接，向服务器发送一个SYN报文段
    * 报文内容
        * 设置`SYN`标志位为`1`
        * 选择一个随机的**初始序列号**(*Initial Sequence Number, ISN_c*)，将其放入**序列号字段**(*Sequence Number*)
        * （可选）携带其他TCP选项，如**最大报文段长度**(*MSS*)等
    * 状态变迁：客户端发送SYN报文后，进入`SYN_SENT`(同步已发送)状态。这意味着客户端等待服务器的确认
2. 第二次握手：服务器发送`SYN-ACK`包(*SYN-ACK - Synchronize-Acknowledge*)
    * 动作：服务器收到客户端的`SYN`报文后，确认可以接受连接请求
    * 报文内容：
        * 设置`SYN`标志位为`1`(表示同意连接)。
        * 设置`ACK`标志位为`1`(表示确认)。
        * 发送自己的一个随机**初始序列号**(*ISN_s*)，放入序列号字段
        * 发送对客户端`SYN`报文的确认号(*ACK = ISN_c + 1*)，放入**确认号字段**
    * 状态变迁：服务器发送`SYN-ACK`报文后，进入`SYN_RCVD`(同步已接收)状态。这意味着服务器等待客户端的最终确认
3. 第三次握手：客户端发送`ACK`包(*ACK - Acknowledge*)
    * 动作：客户端收到服务器的`SYN-ACK`报文后，确认已收到服务器的响应
    * 报文内容：
        * 设置`ACK`标志位为`1`。
        * 发送对服务器`SYN`报文的确认号(*ACK = ISN_s + 1*)，放入确认号字段
        * 序列号字段通常是上一次发送的序列号（即*ISN_c + 1*）
    * 状态变迁：
        * 客户端发送`ACK`报文后，立即进入`ESTABLISHED`(已建立连接)状态
        * 服务器收到客户端的 ACK 报文后，也进入`ESTABLISHED`(已建立连接)状态

这里涉及到TCP报文的几个部分

* 标志位(`SYN`,`ACK`)是布尔值，表示某种控制功能是否启用（通常是0或1）
* 字段(`seq`,`ack`) 是数值，包含具体的序列号或确认号
  * 确认号(*Acknowledgment Number - ack*)：这个字段表示**发送方**期望接收方下一次发送的数据的序列号。也就是说，它确认了发送方已经成功收到了从接收方发来的、直到`ack - 1`为止的所有数据
  * `ACK`标志位为`1`，才表示确认号字段的值是有效的，需要被处理。 即使一个报文没有携带应用数据，只要`ACK`标志位为`1`，它的`ack`字段依然有意义（建立连接够的所有包中`ACK`都被设为`1`，所以`ack`都必须被处理）

至此，TCP 连接正式建立，客户端和服务器可以开始互相发送和接收应用数据了

##### 为什么是三次握手？理解其必要性

三次握手是TCP建立可靠连接的**最少步骤**，多一次或少一次都可能导致问题。其核心目的是为了防止已失效的连接请求报文段突然传到服务器，从而产生错误。

我们通过反例来理解三次握手的必要性

如果是“两次握手”？

1. 客户端发送`SYN`(ISN_c)。
2. 服务器收到`SYN`，回复`SYN-ACK`(ISN_s, ack=ISN_c+1)。服务器认为连接已建立。
3. （缺失第三次握手）

* 问题：假设客户端发送的第一个`SYN`报文滞留在网络中，很久之后才到达服务器。客户端可能因为超时而重发`SYN`，并与服务器成功建立了一个新的连接并完成数据传输，甚至已经关闭了该连接。此时，滞留的旧`SYN`报文才到达服务器。服务器收到这个“过时”的`SYN`，会立即回复`SYN-ACK`，并**认为连接已建立**，然后分配资源等待客户端发送数据。但客户端已经关闭了旧连接，不会理会这个 SYN-ACK，更不会发送数据
* 结果：服务器白白等待，并且为这个实际上已失效的连接分配和浪费了资源。两次握手无法区分“旧连接请求”和“新连接请求”，无效连接请求

为什么不能是“四次握手”？

四次握手虽然也能建立连接，但没有必要，因为它增加了额外的延迟和资源开销，而**不能提供更多的可靠性保障**。三次握手已经足够确保双方都确认了彼此的收发能力

三次握手的核心作用总结

* 第一次握手：客户端发出请求，服务器确认了**客户端的发送能力**
* 第二次握手：服务器回复确认，客户端确认了**服务器的接收能力**和**服务器的发送能力**
* 第三次握手：客户端回复最终确认，服务器确认了**客户端的接收能力**

通过这三步，双方都明确了自己和对方的发送与接收能力，确保了双向通信的准备就绪，有效地避免了历史连接请求的干扰和资源的浪费

##### 相关状态：`CLOSED`、`LISTEN`、`SYN_SENT`、`SYN_RCVD`、`ESTABLISHED`

在三次握手过程中，TCP 连接的状态会发生以下变化：

* `CLOSED`(关闭)：这是TCP连接的初始状态，表示没有连接活动。客户端和服务器在连接建立前都处于这个逻辑状态
* `LISTEN`(监听)：服务器程序启动后，会调用 `listen()` 函数，进入 `LISTEN` 状态，表示服务器已经准备好接收来自客户端的连接请求
* `SYN_SENT`(同步已发送)：客户端发送了`SYN`报文后，进入此状态，等待服务器的SYN-ACK响应
* `SYN_RCVD`(同步已接收)：服务器收到客户端的`SYN`报文并发送`SYN-ACK`报文后，进入此状态，等待客户端的`ACK`确认
* `ESTABLISHED`(已建立连接)：客户端收到`SYN-ACK`后发送`ACK`，服务器收到`ACK`后，双方都进入`ESTABLISHED`状态。此时，连接已完全建立，可以进行数据传输

#### 四次挥手（*Four-way Handshake*）

四次挥手是指在TCP连接的终止阶段，客户端和服务器之间需要交换**四个数据包**来彻底关闭连接。之所以需要四次，是因为TCP连接是全双工的，这意味着数据可以在两个方向上独立传输和关闭。

##### 四次挥手的详细过程

以下是四次挥手过程的时序图

* `u`是客户端在`FIN`报文前的最后一个发送的序列号+1
* `v`是服务器在发送`ACK`报文前的最后一个发送的序列号+1
* `w`是服务器在发送`FIN`报文前的最后一个发送的序列号+1

```mermaid
sequenceDiagram
    participant Client
    participant Server

    Note over Client,Server: 初始状态：ESTABLISHED

    Client->>Server: FIN(FIN=1,ACK=1,seq=u,ack=v)
    Note left of Client: 客户端没有更多数据<br/>状态变为 FIN_WAIT_1

    Server->>Client: ACK(ACK=1,seq=v,ack=u+1)
    Note right of Server: 服务器收到 FIN，确认<br/>状态变为 CLOSE_WAIT

    Client-->>Client: 收到ACK<br/>状态变为 FIN_WAIT_2

    Server->>Client: FIN(FIN=1,ACK=1,seq=w,ack=u+1)
    Note right of Server: 服务器数据发送完毕<br/>状态变为 LAST_ACK

    Client->>Server: ACK(ACK=1,seq=u+1,ack=w+1)
    Note left of Client: 客户端收到FIN，确认<br/>状态变为 TIME_WAIT (2MSL)

    Server-->>Server: 收到ACK<br/>状态变为 CLOSED

    Client-->>Client: 2MSL 时间后<br/>状态变为 CLOSED
    Note over Client,Server: 连接完全关闭
```

对四次挥手过程中的实体及初始状态定义如下

* 客户端：发起关闭请求的一方
* 服务器：被请求关闭的一方
* 初始状态：客户端和服务器都处于`ESTABLISHED`状态，可以进行正常的数据传输

挥手步骤如下

1. 第一次挥手：客户端发送`FIN`包(*FIN - Finish*)
   * 动作：客户端决定关闭连接（例如，用户关闭了浏览器标签页，或者应用程序完成了数据传输）。它向服务器发送一个`FIN`报文段，表示客户端**不再有数据要发送给服务器了**，但仍然可以接收来自服务器的数据
   * 报文内容：
       * 设置`FIN`标志位为`1`
       * 设置`ACK`标志位为`1`(因为连接已建立，所有报文都带`ACK`)
       * `seq`字段：当前发送方（客户端）的序列号
       * `ack`字段：对服务器已接收数据的确认号
   * 状态变迁：客户端发送`FIN`报文后，进入`FIN_WAIT_1`(等待 FIN)状态。这意味着客户端正在等待服务器的确认
2. 第二次挥手：服务器发送`ACK`包
   * 动作：服务器收到客户端的`FIN`报文后，立即发送一个`ACK`报文段作为响应，确认收到了客户端的关闭请求。此时，服务器可能还有数据要发送给客户端
   * 报文内容：
       * 设置`ACK`标志位为`1`
       * `seq` 字段：当前发送方（服务器）的序列号
       * `ack` 字段：对客户端 FIN 报文的确认号（通常是客户端 FIN 报文的`seq + 1`）
   * 状态变迁：
       * 服务器发送`ACK`报文后，进入`CLOSE_WAIT`(关闭等待)状态。这意味着服务器已经收到了客户端的关闭请求，并通知客户端“已经关闭了它的发送方向，但我可能还有数据要发给你”。服务器如果还有数据要发送，可以在这个状态下继续发送
       * 客户端收到服务器的`ACK`报文后，进入`FIN_WAIT_2`(等待最后`FIN`)状态。这意味着客户端等待服务器发送它自己的`FIN`报文
3. 第三次挥手：服务器发送`FIN`包
   * 动作：当服务器的应用程序也完成了所有数据的发送，并准备关闭自己的发送方向时，它会向客户端发送一个 `FIN`报文段
   * 报文内容：
       * 设置`FIN`标志位为`1`
       * 设置`ACK`标志位为`1`
       * `seq`字段：当前发送方（服务器）的序列号
       * `ack`字段：对客户端已接收数据的确认号
   * 状态变迁：服务器发送`FIN`报文后，进入`LAST_ACK`(最后确认)状态。这意味着服务器正在等待客户端的最终 ACK 确认
4. 第四次挥手：客户端发送`ACK`包
      * 动作：客户端收到服务器的`FIN`报文后，发送一个`ACK`报文段作为响应，确认收到了服务器的关闭请求
      * 报文内容：
          * 设置`ACK`标志位为`1`
          * `seq`字段：当前发送方（客户端）的序列号
          * `ack`字段：对服务器`FIN`报文的确认号（通常是服务器`FIN`报文的 `seq + 1`）
      * 状态变迁：
          * 客户端发送`ACK`报文后，进入`TIME_WAIT`(时间等待)状态。客户端会在这个状态下停留一段指定的时间(通常是**`2MSL`**)，之后才会进入`CLOSED`状态。`TIME_WAIT`状态是四次挥手中最特殊也是面试高频考点之一
          * 服务器收到客户端的 ACK 报文后，立即进入`CLOSED`(关闭)状态

至此，TCP 连接彻底关闭，资源被释放

##### 为什么是四次挥手？理解其必要性

之所以需要四次挥手，是因为TCP连接是**全双工**的。这意味着连接的每一方都独立地管理其发送和接收的数据流

* 第一次和第二次挥手：**客户端的发送方向**关闭。客户端通知服务器“我没数据要给你了”，服务器确认收到。此时，服务器仍然可以向客户端发送数据（半关闭状态）
* 第三次和第四次挥手：**服务器的发送方向**关闭。服务器通知客户端“我没数据要给你了”，客户端确认收到

简单来说，当客户端发送`FIN`时，它只是说“我这边的数据发完了”。服务器收到`FIN`后，会回复`ACK`，表示“我知道你没数据发了”。但服务器可能还有数据没有发完，所以它不会立即发送`FIN`，只有当服务器也把数据发完了，它才会发送自己的`FIN`。所以，`FIN`和`ACK`通常是分开的两次发送，而不是像建立连接时的`SYN`和`ACK`那样合并发送。即双方何时关闭接收流是取决于对方是否发了`FIN`包，所以不能保证服务器一定会第一个`ACK`和它自己的`FIN`合并发送

这确保了两个方向的数据流都能优雅地关闭，而不会丢失任何传输中的数据

##### 相关状态：`ESTABLISHED`、`FIN_WAIT_1`、`CLOSE_WAIT`、`FIN_WAIT_2`、`LAST_ACK`、`TIME_WAIT`、`CLOSED`

我们再次整理在四次挥手过程中涉及到的 TCP 状态：

* `ESTABLISHED`(已建立连接)：连接处于正常的数据传输状态
* `FIN_WAIT_1`(等待`FIN`)：客户端发送了`FIN`报文，等待服务器的`ACK`确认
* `CLOSE_WAIT`(关闭等待)：服务器收到了客户端的`FIN`报文，并发送了`ACK`。此时服务器的应用程序可以继续发送数据，等待上层应用发出关闭连接的指令。这是服务器端等待应用关闭自己发送端的状态
* `FIN_WAIT_2`(等待最后`FIN`)：客户端收到了服务器对`FIN`的`ACK`后等待服务器发送它自己的`FIN`报文
* `LAST_ACK`(最后确认)：服务器发送了`FIN`报文，等待客户端的最终`ACK`确认
* `TIME_WAIT`(时间等待)：客户端发送了最后一个`ACK`报文后，进入此状态，等待`2MSL`时间，以确保服务器收到最终的`ACK`并处理网络中可能滞留的报文
* `CLOSED`(关闭)：连接已完全终止，资源被释放

#### `TIME_WAIT`状态

##### `TIME_WAIT` 状态的必要性与存在意义

`TIME_WAIT`状态是主动关闭连接的一方（即发送最后一个`ACK`的一方）在发送完`ACK`报文后，进入的一个特殊等待状态。这个状态会持续一段固定的时间，通常是**2MSL**

`TIME_WAIT` 状态的主要存在意义有两个：

1. 确保最后一个`ACK`报文能够到达服务器
    * 在四次挥手的最后一步，客户端发送的最后一个`ACK`报文可能会在网络中丢失
    * 如果没有`TIME_WAIT`状态，客户端发送完`ACK`之后就直接进入`CLOSED`状态，并释放了端口。此时，如果服务器没有收到客户端的`ACK`，它会超时并**重传**第三次挥手时的`FIN`报文
    * 由于客户端已经处于 `CLOSED` 状态，它会忽略或响应一个`RST`（*Reset*）报文，这可能会导致服务器端收到 `RST`后出现错误
    * 而有了`TIME_WAIT`状态，客户端即使已经发送了ACK，它仍然**保持着该连接的端口和状态**。如果它又收到了服务器重传的`FIN`报文，它会**重新发送`ACK`**，确保服务器能够正确地关闭连接
2. 防止旧连接的报文段在网络中被新连接接收
    * 假设一个客户端和服务器之间的一个连接被关闭了，并且这个连接使用的端口号被立即重用，建立了一个新的连接
    * 如果网络中还滞留着属于旧连接的、延迟到达的数据报文段，这些报文段可能会被新连接接收，导致数据混乱
    * `TIME_WAIT`状态的存在，确保了这个连接使用的端口在**`2MSL`**时间内不会被再次使用。这足以让网络中所有属于旧连接的延迟报文段都**自然消逝**（下一章节解释），从而避免它们对新连接造成干扰

简而言之，`TIME_WAIT`状态是为了保证**TCP连接的可靠性**和**有序性**，是TCP协议在复杂网络环境下自我保护的一种机制

##### 2MSL(*Maximum Segment Lifetime*)的意义

`MSL`是指一个TCP报文段在网络中的**最大生存时间**。它是一个理论值，表示报文段从发送端到达接收端所需的最长时间，即使网络中存在路由环路，报文段最终也会因为其`TTL` (*Time To Live*) 字段过期而被丢弃

* `2MSL` 的时间长度是为了保证**一个报文段来回一趟所需的足够时间**
* 第一个`MSL`：确保客户端发送的最后一个`ACK`能够到达服务器
* 第二个`MSL`：确保服务器重传的`FIN`报文（如果第一个`ACK`丢失）能够到达客户端
* 这样，客户端在`2MSL`时间后进入 `CLOSED` 状态，就可以确保网络中不再存在任何属于该旧连接的报文段了。

RFC 793建议的`MSL`值为2分钟。但在现代系统中，这个值通常被配置为30秒、1分钟等更小的值，以减少`TIME_WAIT` 状态的持续时间

##### `TIME_WAIT`过多的影响及解决方案

尽管`TIME_WAIT`状态对于TCP的可靠性至关重要，但如果系统中存在大量的`TIME_WAIT`状态，也可能带来问题，尤其是在高并发、短连接的应用场景中（如 Web 服务器）

* 端口资源耗尽：每个`TIME_WAIT`状态的连接都会占用一个端口。如果服务器作为主动关闭方（例如关闭空闲连接），并且每秒处理大量短连接，可能会导致端口资源被快速耗尽，新的连接无法建立
* 性能开销：操作系统需要为每个`TIME_WAIT`连接维护一个**控制块**，这会消耗一定的内存资源

解决方案

在某些特定的场景下，可以通过一些操作系统级别的配置来优化或规避`TIME_WAIT`带来的问题。

1. `SO_REUSEADDR`选项
    * 作用：这是一个套接字选项，允许一个处于`TIME_WAIT`状态的端口被立即重用，用于绑定一个新的套接字
    * 使用场景：主要用于**服务器端**，当服务器重启时，如果上一个实例的某些端口还处于`TIME_WAIT`状态，设置此选项可以立即使用这些端口，避免重启失败
    * 副作用：这个选项**并没有**解决旧报文干扰新连接的问题。因为它只是允许端口重用，并没有缩短 `TIME_WAIT`的时间。在某些情况下，这可能会导致新连接收到旧连接的延迟报文
2. 缩短`TIME_WAIT`的时间
    * 在Linux系统中，可以通过修改`/proc/sys/net/ipv4/tcp_tw_reuse`和`/proc/sys/net/ipv4/tcp_tw_recycle`这两个内核参数来**复用或快速回收**`TIME_WAIT`状态
      * `tcp_tw_reuse`：只对客户端有效，允许将`TIME_WAIT`状态的端口用于新的连接，但要求新的连接的序列号大于旧连接
      * `tcp_tw_recycle`：在Linux 4.12版本之后已被移除，因为它在NAT环境下存在严重问题。在旧版本中，它可以更激进地快速回收`TIME_WAIT`状态的套接字。
    * 需要注意：调整这些参数会牺牲一部分可靠性来换取性能，因此需要谨慎使用，特别是当网络中存在大量NAT设备时
3. 负载均衡和连接池
    * 在高并发场景下，使用**负载均衡器**或**连接池**是更优的解决方案
    * 负载均衡器可以将请求分发到多个服务器，分摊端口压力。这是一种横向扩展的方案
    * 连接池通过维护长连接来减少短连接的建立和关闭次数，从而从根本上减少`TIME_WAIT`状态的产生。这需要转化问题，而不是简单地解决问题

`TIME_WAIT` 状态是TCP协议为了**可靠性**而做出的设计权衡。虽然在某些高并发场景下它会带来资源压力，但通常不应该被简单地禁用。正确的做法是理解它的存在意义，并根据具体应用场景，通过适当的配置或架构设计来优化，而不是粗暴地绕过它

### UDP的连接管理

UDP是非面向连接的协议，所有的连接管理机制需要在应用层实现

## 可靠性保障机制

### TCP的可靠性保障机制

#### 序列号与确认应答

这是TCP可靠性的基石，它们协同工作，确保数据**不丢失、不重复且按序到达**

* **序列号**(*Sequence Number* - `seq`)
  * 作用：序列号是发送方对数据进行编号的依据。每一个TCP报文段都会有一个序列号，它标识了该报文段中第一个数据字节在整个数据流中的位置
  * 工作原理：在连接建立时，双方会协商一个初始序列号(ISN)。之后发送的每一个数据报文段，其序列号都会在上一个报文段的序列号基础上，加上**已发送的字节数**。这使得接收方能够对收到的乱序报文段进行排序，并识别重复的报文段
* **确认应答**(*Acknowledgment Number* - `ack`)
  * 作用：确认号是接收方用来告诉发送方“我收到了哪些数据”的。它表明接收方**期望收到的下一个字节的序列号**
  * 工作原理：每当接收方收到一个报文段后，会发送一个确认报文，报文中的`ack`字段会设置为已收到的数据流的**下一个**预期序列号。例如，如果收到了序列号从100到199的数据，那么确认号就会是`200`，表示“我已经收到了 199之前的所有数据，我期望你接下来给我发从200开始的数据”
* **累计确认**(*Cumulative Acknowledgment*)
  * 概念：TCP使用的是**累计确认**机制。这意味着一个确认号 `N` 并不只是确认了序列号`N-1`的数据，而是确认了从连接开始到序列号`N-1`为止的所有数据
  * 优点：这种机制可以减少确认报文的数量。即使发送方发送了多个报文段，接收方也只需要发送一个确认报文，就可以一次性确认之前所有已收到的数据。这大大提高了效率

#### 超时重传(*Retransmission Timeout* - RTO)

序列号和确认号解决了“有序、不丢包”的问题，但如果网络环境不好，报文段真的丢失了怎么办？超时重传就是为此而生的

* 机制
    1. 发送方发送一个报文段后，会启动一个定时器
    2. 如果定时器在到期之前收到了该报文段的确认应答，那么定时器就会被取消
    3. 如果定时器到期，但发送方没有收到确认应答，它就认为该报文段已经丢失，并重新发送该报文段。
* RTO动态调整
  * **RTO**是指从发送报文到重发报文所等待的超时时间。如果RTO固定不变，就会有问题：如果RTO太短，会发生不必要的重传，加重网络负担；如果RTO太长，会影响传输效率
  * 由于网络状况是动态变化的（时延、拥塞等），TCP采用动态的RTO算法。它会根据每一次通信的**往返时间**(*RTT, Round Trip Time*)来动态地调整RTO的值
  * **RTT**是指从发送数据到收到对应确认的时间。TCP会测量并记录每次报文段的RTT，然后使用**加权平均算法**来估算一个**平滑的RTT**(*Smoothed RTT*)，并据此来计算RTO。这个计算会考虑RTT的波动性，以确保RTO的值既不过短也不过长

当一个数据包发出去后，在规定的`RTO`时间内都没有收到任何确认，发送方会认为这个数据包已经彻底丢失了。这种“完全沉默”通常意味着网络中发生了严重的拥塞，甚至可能导致多个数据包连续丢失。面对这种情况，TCP认为之前对网络带宽的乐观估计（即`cwnd`和`ssthresh`的值）是完全错误的，因此必须采取最保守的策略

1. 将`ssthresh`设置为当前`cwnd`的一半
2. 将`cwnd`直接重置为1个MSS
3. 重新进入“慢启动”阶段，从头开始探索网络容量

#### 校验和(*Checksum*)

校验和是TCP协议提供的最简单、最基础的可靠性保障机制

* 目的
  * 校验和是一个用于检测数据**完整性**的简单算法。它确保报文段在传输过程中没有因为**比特错误**（如电磁干扰）而损坏
* 工作原理
    1. 发送方：在发送数据之前，对整个报文段（包括头部和数据）执行一个简单的计算，得到一个校验和值，并将其放入报文段的校验和字段
    2. 接收方：收到报文段后，也会执行同样的计算。
    3. 校验：如果计算结果与报文段中携带的校验和字段的值不匹配，就表明数据在传输过程中发生了错误
    4. 处理：接收方会丢弃这个损坏的报文段，TCP依赖超时重传机制来等待发送方重发正确的数据

需要注意的是，校验和只是一种**弱校验**，它能检测出大部分错误，但不能保证100%的准确性。在应用层面，通常还会使用更强的校验算法（如MD5或SHA-256）来确保数据的完整性

正是因为 TCP 提供了上述一系列复杂的机制，才使其成为一个可靠的协议，适用于对数据完整性要求极高的应用，如文件传输、网页浏览等。

### UDP的可靠性保障机制

和TCP提供的可靠性保障机制对比

* 序列号和确认应答：无。UDP的数据报是独立的，没有编号和确认机制
* 超时重传：无。UDP不会重传丢失的报文
* 校验和：有，但它是**可选的**。如果发送方没有计算校验和，那么校验和字段会被全零填充。

## 传输效率与控制机制

### TCP的传输效率与控制机制

传输效率与控制机制保证了TCP在提供可靠性的同时，也能高效、健康地传输数据

#### 滑动窗口(*Sliding Window*)

滑动窗口是TCP提高传输效率的核心手段。它允许发送方在**不等待每个数据包确认的情况下，连续发送多个数据包**

* 目的
  * 提高传输效率：如果发送方每发送一个数据包都必须等待确认，那么网络延迟会严重影响吞吐量。滑动窗口允许发送方“一次性”发送一批数据，极大地减少了等待时间
  * 实现流量控制：**滑动窗口的大小由接收方控制**，从而限制了发送方的发送速率，防止接收方缓冲区溢出
* 窗口大小：发送窗口与接收窗口
  * 发送窗口(*Send Window*)：发送方维护的窗口。它决定了发送方**当前还能发送多少字节的数据**。发送窗口的大小等于`min(接收窗口, 拥塞窗口)`，这是流量控制和拥塞控制共同作用的结果
  * 接收窗口(*Receive Window*)：接收方维护的窗口。它决定了接收方**还有多少空闲缓冲区可以接收数据**。接收方通过在`ACK`报文中将这个值告诉发送方，来实现流量控制
* 零窗口问题(*Zero Window Problem*)
  * 原因：当接收方的应用程序处理数据太慢，导致其接收缓冲区满载时，接收方会向发送方通告一个`接收窗口 = 0` 的`ACK`报文
  * 处理：发送方收到“零窗口”通知后，会**暂停发送数据**。但是，为了避免死锁（如果通知窗口变大的`ACK`报文丢失），发送方会启动一个**持久计时器**（*Persist Timer*）。当计时器到期后，发送方会发送一个**窗口探测报文**（*Window Probe*），询问接收方窗口是否已变大。这个过程会一直持续，直到接收方发送一个窗口不为零的`ACK`报文

#### 流量控制(*Flow Control*)

流量控制是一个**点对点**（端到端）的机制

* 目的：协调**发送方和接收方的速率**，防止发送方发送数据过快，导致接收方的缓冲区溢出
* 实现方式：完全依赖于**滑动窗口**。接收方通过`ACK`报文中的`接收窗口`字段来告诉发送方自己还能接收多少数据。发送方根据这个值来调整自己的发送速率，确保不超过接收方的处理能力

#### 拥塞控制(*Congestion Control*)

拥塞控制是一个**全局性**的机制

* 目的：协调**发送方和整个网络的速率**，防止发送数据过多，导致网络中的路由器和交换机队列溢出，从而引起全局性的性能下降
* 拥塞窗口(*Congestion Window* - cwnd)
  * TCP引入了一个名为**拥塞窗口**的概念，它由发送方动态维护
  * 拥塞窗口的大小是发送方能够向网络中发送的**最大数据量**
  * 拥塞控制算法的核心就是动态调整`cwnd`的值
* 四种核心算法(*TCP Reno/Cubic*)
  1. 慢启动(*Slow Start*)
     * 目的：在连接刚建立或网络空闲时，快速探测网络的带宽
     * 原理：`cwnd`的初始值为一个较小的值（例如1或2个MSS）。每当收到一个ACK，`cwnd`就会**指数级增长**
     * 为什么叫“慢启动”：虽然是指数增长，但相对于带宽来说，它的增长过程是从一个很小的值开始的，所以被称为“慢启动”
  2. 拥塞避免(*Congestion Avoidance*)
     * 目的：当`cwnd`达到一个预设的阈值（`ssthresh`，慢启动阈值）后，进入拥塞避免阶段
     * 原理：`cwnd`的增长模式从指数增长变为**线性增长**。每当收到一个ACK，`cwnd` 缓慢增加
     * 为什么要线性增长：这是为了在不引起网络拥塞的前提下，继续探索网络的容量
  3. 快速重传(*Fast Retransmit*)
     * 目的：在没有等到超时的情况下，快速重传丢失的数据包
     * 原理：当发送方收到**三个重复的ACK**（即确认号都相同的ACK报文）时，它就会立即**重传**那个被重复确认的数据包，而无需等待`RTO`超时。这大大减少了丢包后的恢复时间
  4. 快速恢复(*Fast Recovery*)
     * 目的：在快速重传之后，避免重新进入慢启动阶段，从而更温和地恢复传输
     * 原理：发送方在执行快速重传后，会调整`cwnd`和`ssthresh`的值，并继续以线性增长的方式恢复传输，而不是像超时重传那样将`cwnd`重置为1
     * 处理方式
       * 将`ssthresh`设置为当前cwnd的一半
       * 将`cwnd`设置为`ssthresh+3`个MSS
       * 直接进入“拥塞避免”阶段

发送方在接收到某个报文的`ACK`之前，必须具备重发这个包的能力。这要归功于TCP内部的一个关键机制——**发送缓冲区**（*Send Buffer*）

* 发送缓冲区的角色
  * 当应用程序将数据交给TCP层发送时，这些数据并不会直接被丢弃。它们首先会被**复制**一份，并放入一个名为发送缓冲区的内存区域
  * 发送方将缓冲区中的数据打包成报文段，并发送到网络上
  * TCP会持续地在发送缓冲区中保留这些已发送但尚未被确认的数据
* 重发的能力
  * 当发送方收到对应报文的`ACK`后，它会认为这个数据已经安全到达，此时才会将这个数据从发送缓冲区中删除
  * 如果定时器超时（RTO）或收到重复的ACK（快速重传），发送方可以立即从发送缓冲区中找到并重新发送这个丢失的报文，而不需要向应用程序请求数据

> 发送缓冲区通常使用环形缓冲区（双指针，头指针和ACK确认报文指针，需要提前分配空间，静态结构）实现。还可以使用链表，但是占用内存更大，需要存储指针，并且容易产生内存碎片

#### 流量控制与拥塞控制的区别与联系

| 对比项         | **流量控制 (Flow Control)** | **拥塞控制 (Congestion Control)** |
| :------------- | :-------------------------------------------------------------- | :---------------------------------------------------------------- |
| 关注点 | **接收方**的处理能力                                            | **整个网络**的负载                                                |
| 控制对象 | 协调**发送方和接收方**的速率                                    | 协调**发送方和网络**的速率                                        |
| 实现机制 | 接收窗口（`rwnd`）                                                | 拥塞窗口（`cwnd`）、慢启动、拥塞避免、快速重传、快速恢复等算法 |
| 核心问题 | 防止接收方**缓冲区溢出** | 防止网络**拥塞崩溃** |
| 作用范围 | 点对点（端对端）                                                | 全局性                                                            |

流量控制和拥塞控制共同决定了TCP的发送速率。发送方最终的发送窗口大小是两者中较小的一个，即`实际发送窗口大小 = min(接收窗口, 拥塞窗口)`。这样，TCP既能保证不撑爆接收方的缓冲区，又能防止自己对整个网络造成太大的负担

### UDP的传输效率与控制机制

* UDP没有流量控制。它只管发送数据，不关心接收方是否能处理，这可能导致接收方丢包
* UDP也没有拥塞控制。这意味着UDP应用会以应用允许的最大速度发送数据，完全不考虑网络状况。这在某些场景下（如实时音视频）可以降低延迟，但在网络拥塞时，会加剧丢包，甚至导致“拥塞崩溃”

## 常见问题与优化

### TCP的常见问题与优化

#### TCP粘包与拆包(*TCP Segmentation*)

TCP粘包与拆包是由于TCP的**面向字节流**特性而引起的问题

* 产生原因
  * TCP面向字节流：TCP传输的单位是字节流，它没有消息边界的概念。当应用程序向TCP缓冲区写入数据时，TCP会根据自身的发送策略（如缓冲大小、Nagle算法等）来决定何时将缓冲区的数据打包成一个或多个报文段发送
  * Nagle算法：Nagle算法的引入是为了**提高网络利用率**，它会延迟发送小数据包，将它们合并成一个更大的报文段。这可能导致本应独立发送的两个小消息被“粘”在一起
  * 接收方处理速度：接收方应用程序从TCP缓冲区读取数据时，可能一次性读入多个消息的数据，或分多次读取一个完整的消息
* 解决方案
  * **定长消息**：协议规定每个消息的长度都是固定的。接收方每次读取固定长度的数据即可
  * **分隔符**：在每个消息的末尾添加一个特殊的分隔符（例如 `\r\n`）。接收方读取数据直到遇到分隔符，就认为一个消息结束
  * **TLV协议头**(*Type-Length-Value*)： 最常用且最可靠的方法。在每个消息前加上一个包含**消息类型和消息长度**的协议头。接收方首先读取协议头，然后根据协议头中的长度字段精确地读取整个消息

#### Nagle算法与延迟ACK

这两个机制都是为了提高TCP连接的效率，但都可能在特定情况下引入延迟

* Nagle算法
  * 目的：减少网络中小数据包的数量，避免**糊涂窗口综合征**（*Silly Window Syndrome*），提高网络吞吐量
  * 原理：
      1. 当一个TCP连接中存在**未确认的数据**时，发送方不会发送新的小数据包（小于MSS），而是将它们缓冲起来
      2. 直到已发送的数据得到确认，或者累积的数据量达到MSS大小，发送方才会将所有缓冲的数据打包成一个报文段发送
* 延迟ACK(*Delayed Acknowledgment*)
  * 目的：同样是为了减少网络流量。它避免了每收到一个数据包就立即发送一个`ACK`，而是将多个`ACK`合并，或者将`ACK`和发送方要发送的数据合并到同一个报文段中
  * 原理：接收方在收到数据后，不会立即发送确认，而是会等待一段时间（通常是几十到几百毫秒），看看是否有数据要发给对方。如果有，就会将ACK和数据一起发送。如果没有，等待时间到了之后再单独发送ACK
* 可能带来的问题
  * 延迟：如果发送方发送了两个小数据包，并且第一个包的`ACK`因为**延迟ACK**没有立即返回，Nagle算法就会一直等待。这会导致第二个数据包的发送延迟，从而影响实时性，在游戏、SSH远程登录等对延迟敏感的应用中，会造成卡顿
* 优化：
  * `TCP_NODELAY`选项：这是最常见的解决方案。应用程序可以设置`TCP_NODELAY`选项来禁用Nagle算法。这会让小数据包立即发送，而无需等待确认。在对延迟有严格要求的应用中，通常会启用此选项

#### TCP的`keep-alive`机制

* 目的
  * 探测并维护连接的**存活性**，防止连接因为长时间空闲而被网络中的防火墙或NAT设备关闭
  * 当网络中断时，能够及时发现连接中断，避免服务器长时间等待一个已经断开的客户端
* 原理
  * 如果一个TCP连接在一段时间（例如2小时）内没有数据交换，TCP就会发送一个**不包含任何数据的保活探测报文段**
  * 如果收到对方的响应，则认为连接正常，计时器重置
  * 如果没有收到响应，TCP会在一段时间内重试几次
  * 如果重试后仍然没有响应，TCP就会认为连接已断开，并通知应用程序

TCP的`Keep-alive`机制默认是关闭的。开发者使用`setsockopt`函数，设置`SO_KEEPALIVE`来启用这个功能，常用的配置参数如下，在Linux系统上，可以通过`sysctl`来查看和修改

* `net.ipv4.tcp_keepalive_time`：在TCP连接上没有数据传输的**空闲时间**，之后内核将开始发送第一个保活探测报文，通常7200s
* `net.ipv4.tcp_keepalive_intvl`：在未收到保活探测报文的应答时，**后续探测报文发送的间隔时间**，通常75s
* `net.ipv4.tcp_keepalive_probes`：在连接被认为“死亡”之前，内核**发送的探测报文的最大数量**，通常为9

单个套接字可以使用`IPPROTO_TCP`级别的选项来完成配置任务，对应上面的三条配置项的应用级配置是`TCP_KEEPIDLE`、`TCP_KEEPINTVL`、`TCP_KEEPCNT`

#### SYN洪泛攻击(*SYN Flood*)

* 原理
  * 攻击者利用TCP三次握手的漏洞发起攻击
  * 攻击者使用伪造的IP地址向服务器发送大量的`SYN`报文
  * 服务器收到`SYN`后，会为每一个请求分配资源（例如建立一个**连接控制块**），并发送`SYN-ACK`报文
  * 然而，由于攻击者的IP是伪造的，服务器永远无法收到第三次握手所需的`ACK`报文
  * 结果就是服务器的连接队列被大量处于`SYN_RCVD`状态的半开连接耗尽，无法再接受新的合法连接请求，导致拒绝服务
* 防御方法
  * `SYN` Cookies
    * 原理：服务器在收到`SYN`报文后，**不立即分配资源**，而是计算出一个特殊的“cookie”值，将其作为`SYN-ACK` 报文的初始序列号
    * 优点：只有当客户端发送第三次握手的`ACK`报文时（且该报文携带了正确的“cookie”），服务器才会分配资源，从而避免了资源被恶意消耗
  * `SYN` Proxy
    * 原理：在服务器前设置一个代理服务器（如防火墙），由代理服务器代替服务器与客户端进行三次握手。当代理服务器完成握手后，再将连接请求转发给后面的真实服务器
  * 防火墙/IDS(*Intrusion Detection System*)
    * 防火墙可以配置规则来限制来自单个IP地址的 `SYN` 报文数量，或者在识别出攻击模式后主动丢弃相关报文

### UDP的常见问题与优化

UDP本身没有这些复杂的问题。它的问题本质上是其**特性**带来的副作用

1. 不可靠性与乱序
    * 问题：UDP不保证数据报的到达、顺序和完整性
    * 优化/解决方案：需要在应用层实现自己的**可靠性协议**。例如，QUIC协议就是在UDP之上实现了可靠的、有序的传输
2. 没有拥塞控制
    * 问题：UDP流量可能导致网络拥塞，甚至“拥塞崩溃”
    * 优化/解决方案
        * 应用程序需要自己实现**拥塞控制算法**。例如，某些实时音视频协议会根据丢包率、延迟等指标来动态调整码率
        * 使用基于UDP的协议（如QUIC），它们内置了先进的拥塞控制算法（如`BBR`），能够更好地适应网络状况
3. 大报文分片
    * 问题：UDP数据报在IP层可能被分片，任何一个分片丢失都会导致整个数据报需要被重传
    * 优化/解决方案：在应用层限制UDP数据报的大小，使其不超过`MTU`(*Maximum Transmission Unit*)，以避免IP分片

## TCP的扩展与高性能

TCP协议在设计之初，网络带宽和延迟都远低于现在。为了适应高速、高延迟的网络环境，TCP引入了一系列可选的扩展，这些扩展通常在三次握手时通过TCP头部选项进行协商

### 窗口扩大因子(*Window Scale Option*)

* 问题：TCP头部中的窗口大小字段只有16位，最大只能表示65535字节的窗口。在高速网络（高带宽）和高延迟（长距离）的环境下，这个窗口大小太小，会严重限制吞吐量
* 解决方案：窗口扩大因子扩展允许将16位的窗口大小字段左移，从而将窗口大小扩展到最高**1GB**
* 工作原理：在三次握手时，通信双方会交换各自的窗口扩大因子（一个`0-14`的整数）。实际的窗口大小是`窗口大小字段的值 * (2 ^ 窗口扩大因子)`。这使得 TCP 能够充分利用**高带宽延迟积**（*Bandwidth-Delay Product*），实现更高的吞吐量

### 时间戳选项(*Timestamps Option*)

* 问题
    1. 序列号回绕：在高速网络中，32位的序列号可能在很短的时间内用完并重新开始（回绕），导致接收方无法区分新旧数据包
    2. `RTT`估算不准确：当发生重传时，发送方无法区分收到的`ACK`是对原始报文的确认还是对重传报文的确认，导致`RTT`估算不准确。也就是说如果认为接收的`ACK`是原始报文的确认，那么得到的`RTT`就会过大，那么`RTO`也会被调得过大导致传输速率下降
* 解决方案：时间戳选项在TCP头部中添加了两个4字节的字段
  * 发送方时间戳(*TSval*)：发送方在发送报文时的时间戳
  * 回显时间戳(*TSecr*)：接收方将收到的`TSval`原样回传
* 工作原理
  * 解决序列号回绕：接收方可以根据时间戳来判断一个序列号回绕的报文是旧的还是新的
  * 准确估算`RTT`：发送方可以通过比较当前时间与回显的时间戳来精确地计算`RTT`，即使报文发生了重传

### 选择性确认(*Selective Acknowledgment - SACK*)

* 问题：传统的TCP采用**累计确认**机制。如果发送方发送了1、2、3、4、5五个报文段，其中3号报文段丢失，接收方只能持续发送对2号报文的`ACK`。发送方必须等到超时或收到3个重复ACK后，才能重传3号和它之后的所有报文（4、5）。这导致了不必要的重传，降低了效率
* 解决方案：`SACK`扩展允许接收方在`ACK`报文中**精确地告知发送方哪些数据段已经收到*
* 工作原理：当接收方收到1、2、4、5号报文时，它会发送一个`ACK`报文，其中包含
  * 累计确认号：`ack=3`（表示已收到2号报文）
  * `SACK`选项：告知发送方它已经收到了4号和5号报文
  * 发送方收到这个`SACK`报文后，就知道只有3号报文丢失，只需要重传这一个报文段即可，大大提高了重传效率

在Linux中，`SACK`选项使用`net.ipv4.tcp_sack`开启，设置为`1`，对于开发者来说，在建立TCP连接过程中协商是透明的，只要开启选项后即启用

#### TCP的`BBR`拥塞控制算法

* 问题：传统的拥塞控制算法（如`Cubic`）主要基于**丢包**来判断网络是否拥塞。这在高带宽、大缓存的网络中存在问题：只有当缓冲区满载并开始丢包时，算法才会减速。这会导致网络链路被填满，造成高延迟
* 解决方案：TCP的BBR(*Bottleneck Bandwidth and Round-trip propagation time*)算法通过**估算**网络的**瓶颈带宽**和**最小往返时间**来控制发送速率
* 工作原理
  * `BBR`不再依赖丢包作为拥塞信号
  * 它通过发送**特定模式的数据包**，持续探测网络的**瓶颈带宽**（即网络的最大吞吐量）和**最小RTT**（即网络延迟）
  * 发送速率被限制在**瓶颈带宽**和**最小RTT**的乘积（即带宽延迟积），从而在不填满网络缓冲区的前提下，实现高吞吐量和低延迟
* 优势
  * 在高带宽、高延迟网络中表现更好
  * 避免了传统算法在丢包前填满缓冲区造成的延迟
  * 在有损网络环境中，不会因为丢包而过度减速

## TCP协议面试高频问题

### 基础与核心机制

#### TCP连接建立与终止

##### 请详细描述 TCP 三次握手和四次挥手的过程，包括每个阶段的状态变迁和报文交换的细节

TCP的三次握手过程：初始状态，服务器端是LISTEN，客户端是CLOSED，首先客户端发送SYN包（seq=c,SYN=1），进入SYN_SENT状态，服务器接收到后发送SYN-ACK包（seq=s,SYN=1，ACK=1,ack=c+1）之后进入SYN_RCVD状态，客户端接收到后发送ACK包（seq=c+1,ACK=1,ack=s+1）之后进入ESTABLISHED状态，服务器接收到客户端最终的ACK包后进入ESTABLISHED状态

TCP的四次挥手过程：假设发送端为主动关闭方，接收端为被动关闭方，开始两者状态都是ESTABLISHED。首先发送端发送FIN包（seq=s,FIN=1,ACK=1,ack=r)，之后进入FIN_WAIT1状态，此时发送端保证不再发送任何消息，接收端接收到FIN包之后发送ACK包（seq=r,ACK=1,ack=s+1），之后进入CLOSE_WAIT状态，发送发接收到这个ACK包后会进入FIN_WAIT2状态。当接收端准备好不再发送任何消息时，发送一个FIN包（seq=r1,ACK=1,FIN=1,ack=s1），之后进入LAST_ACK状态，然后发送端接收到FIN包之后发送最后一个ACK包（seq=s1,ACK=1,ack=r1+1），之后状态变为TIME_WAIT，在这个状态停留2MSL，之后设置自己的状态为CLOSED，接收端接收到最后一个ACK包之后，设置自己状态为CLOSED

##### 解释为什么是“三次握手”而不是“两次或四次”？为什么是“四次挥手”而不是“三次”？简述 `TIME_WAIT` 状态的意义和作用，以及它为什么通常是2MSL

如果是两次握手，服务端无法确认自己的ACK包是否真的被客户端接收，客户端也无法确认自己的SYN包被服务端接收到。并且如果一个SYN包在网络中滞留，服务端之后接收到了这个SYN就直接创建了一个新连接，但实际上并没有对应的客户端存在。这两种情况都会浪费服务器资源。因为三次握手后，客户端和服务端都已经准备好收发消息了，第四次握手就是一个发送普通消息的过程，没有额外意义，还会增加通信开销和延迟。如果是三次挥手，接收端不等待发送端的ACK包就设置为CLOSED状态，此时如果这个FIN包丢失，发送端会保持在FIN_WAIT2状态，认为接收端可能还会继续发送消息，这会导致资源浪费和连接关闭错误。TIME_WAIT状态有两个意义，一是保证发送端最后的ACK被接收端收到，如果ACK丢失，发送端在这个状态下还能重传，二是防止旧连接信息干扰新连接，也就是这个ACK被当作新连接的ACK包被接收端处理。MSL是一个IP数据包在网络中能够存活的最大时间，超过这个时间，报文会因为TTL耗尽被丢弃。2MSL中第一个是确保发送端发送的最后一个ACK能够到达接收方，如果这个ACK丢失，那么接收端会重传FIN，第二个MSL是保证发送端接收到接收端重发的FIN，在2MSL的时间内，可以确保一个新连接复用相同的IP地址和端口时，网络上不存在任何属于旧连接、可能造成混淆的报文

##### 如果服务器在 `CLOSE_WAIT` 状态停留时间过长，可能是什么原因？会导致什么问题？

如果服务器在CLOSE_WAIT停留时间过长，说明服务器在准备好关闭连接之前积压了大量消息需要传给客户端，或者服务器的IO资源长时间无法分配到这个连接上，也就是说服务器程序没有及时关闭连接，TCP协议栈无法发送FIN包，这通常是程序bug。这种情况会导致客户端的关闭过程被阻塞在FIN_WAIT2状态中，等待服务器的FIN包，这会持续占用客户端的系统资源（端口、内存等），影响客户端性能

##### 请分别列举客户端和服务器在四次挥手过程中可能出现的状态，并解释其含义

三次握手和四次挥手过程中可能出现的状态描述

* LISTEN：握手前服务端的状态
* CLOSED：双方处于未连接的状态
* SYN_SENT：第一次握手，客户端发送SYN包后所处状态，
* SYN_RCVD：第二次握手，服务端发送了SYN-ACK包后所处的状态
* ESTABLISHED：第三次握手后双方所处的状态
* FIN_WAIT1：第一次挥手，发送端发送FIN包后的状态，等待接收端的ACK
* FIN_WAIT2：第二次挥手，发送端接收到对之前FIN包的ACK之后所处的状态，接收端依旧可能在此状态下发送数据
* CLOSE_WAIT：第二次挥手，接收端发送ACK包后的状态，表示已经知道发送端关闭发送通道
* LAST_ACK：第三次挥手，接收端发送一个FIN包，表示自己已经关闭发送通道，并且等待发送端对此FIN包的ACK包，收到后进入CLOSED状态
* TIME_WAIT：第四次挥手，发送端发送最后一个ACK包，等待一段时间，持续2MSL，确认ACK包到达接收端并且防止旧连接的ACK包影响新连接，之后进入CLOSED状态

#### TCP的可靠性保障

##### TCP是如何保证数据传输的可靠性、有序性和完整性的？请至少从序列号、确认应答、超时重传和校验和四个方面进行详细阐述

TCP每个报文段都有序列号，标识该报文段的第一个数据字节在整个数据流中的位置，客户端开始发送连接请求时会生成一个随机的起始序列号，服务端在回应SYN-ACK时也会生成一个随机的初始序列号。然后在之后的所有通信包中，都使用确认应答（ack字段）的值表示自己已经接收到了(ack-1)之前的所有序列号的内容，TCP有超时重传机制（RTO），即在RTO时间内没有接收到对方对已发送包的ACK确认就会重传这些包，并且TCP提供了校验和机制，通过对接收到的整个报文段进行校验和计算来确定报文段在传输过程中没有被损坏，这些机制保证了TCP通信的可靠性，即完整、不丢失、不重复、有序的传输特点

##### 解释TCP的**累计确认**机制。它与选择性确认(SACK)有何区别和联系？为什么需要SACK？

TCP的累计确认机制是通过报文段的ack字段的值来实现的，它标识了此端已经成功接收了对端(ack-1)之前的所有报文段。累计确认机制的问题是，在一段连续报文中，如果中间某个报文段丢失，那么发送端要么等待确认超时，或者等待它之前的报文段的确认包连续发送3次，之后会重传丢失报文以及之后的所有报文，这会导致无效发送。引入SACK机制后，接收端发送的确认报文中会指定ack为丢失报文的序列号，然后额外设置SACK的值为接收到的其它报文，此时发送端只需要重传丢失报文即可

##### 详细说明 TCP 的**超时重传机制**，以及 RTO (Retransmission Timeout) 是如何动态调整的。与传统的固定超时相比，动态调整的优势是什么？

TCP的超时重传机制是在RTO时间内，如果发送端没有收到已发送报文的确认ACK，就会尝试重新发送这个报文，RTO的值是动态确定的，使用一些算法（Jacobson/Karels算法）来计算一个平滑的RTT估计值，基于这个值加一些安全余量确定RTO。如果RTO是固定值，过大会导致通信延迟上升，过小又会导致降低通信的性能和资源浪费（频繁发送已经被确认的报文），动态调整的RTO可以在延迟和通信性能之间取得一个平衡值

##### 在发生数据包丢失时，TCP 的**快速重传**和**超时重传**分别会在什么情况下触发？它们在拥塞控制策略上有什么核心区别？

发生数据包丢失时，当发送端在RTO时间内没有接收到对端对已发送报文的ACK确认，会触发超时重传，而如果连续3次接收到对端对同一个报文的ACK确认并且这些ACK报文的确认号都指向还未被确认的报文段的下一个期望序列号，就会触发快速重传，快速重传可以改善网络延迟状态，通常RTO时间属于一个报文被认为丢失的最大时间，而快速重传机制要比超时重传更快，快速重传机制是TCP连接的拥塞控制策略中快速恢复的一部分，避免了整个窗口的停顿，而超时重传是TCP连接的可靠性保证措施之一

#### 流量与拥塞控制

题目描述：滑动窗口与流量控制

* 详细解释 TCP **滑动窗口**的工作原理，包括发送窗口和接收窗口的概念。
* 流量控制是如何通过滑动窗口实现的？请举例说明“零窗口问题”以及 TCP 如何解决它。
* 对比 UDP，为什么 UDP 不需要流量控制？

题目描述：拥塞控制

* 解释 TCP **拥塞控制**的目的和必要性。
* 详细阐述 TCP 拥塞控制的四种经典算法（慢启动、拥塞避免、快速重传、快速恢复）的工作原理、状态变迁及其 `cwnd` (拥塞窗口) 和 `ssthresh` (慢启动阈值) 的变化。
* 相较于传统的拥塞控制算法（如 Cubic），**TCP BBR** 有何不同和优势？它主要关注哪些指标来避免拥塞？
* 在实际应用中，如果服务器的连接出现大量 `SYN_RCVD` 状态的连接，或者 `TIME_WAIT` 状态的连接过多，可能是什么原因？你会如何排查和优化？

### 优化与特性

问题描述：TCP 优化选项

* 解释 **Nagle 算法**和**延迟 ACK** 的目的和原理。它们在什么场景下可能导致性能问题？如何通过 `TCP_NODELAY` 选项进行优化？
* TCP 的**窗口扩大因子 (Window Scale Option)** 和**时间戳选项 (Timestamps Option)** 分别解决了什么问题？它们在高带宽、高延迟网络中有何重要性？
* TCP **Keep-alive** 机制的作用和原理是什么？它与应用层的心跳机制有何区别？Keep-alive 相关的系统参数有哪些，以及如何在应用代码层面进行调整？

问题描述：TCP 粘包与拆包

* 什么是 TCP **粘包**和**拆包**问题？产生的原因是什么？
* 请列举并详细说明至少三种解决 TCP 粘包拆包的常用方法。你在实际项目中会如何选择和设计？

### UDP 与 QUIC

问题描述：UDP 协议

* TCP 和 UDP 在设计哲学和应用场景上有何本质区别？请举例说明各自适合的应用场景。
* 既然 UDP 是不可靠的，为什么还有很多应用（如 DNS、视频直播、QUIC）选择基于 UDP 构建？它们是如何解决 UDP 不足的？

问题描述：QUIC 协议

* QUIC 协议的设计目的是什么？它解决了 TCP 的哪些痛点？
* 请列举并详细解释 QUIC 的至少三个核心特性或技术，例如多路复用、0-RTT 连接建立、连接迁移等。
* QUIC 是如何避免 TCP 的**队头阻塞**问题的？
