# 6824学习笔记

## 简介

如果能用一台计算机完成工作，就不要使用分布式系统

为什么要开发分布式系统

1. 高性能：使用更多的CPU、内存和硬盘来获取更高的性能
2. 容错（fault tolerance）：需要两台计算机做同样的事情，一台出问题另一台还可以服务
3. 天然符合分布式架构的系统：例如跨国交易，两个系统运行在不同的国家
4. 安全：每个系统运行在自己的环境中，对对方的代码互不信任

系列课程主要围绕1，2点讲述

设计分布式系统会遇到的挑战

1. 并行：每台计算机都在并行运行
2. 部分错误（partial failure）：单机环境可以长时间运行，但是当集群规模变大之后总是会有部分出问题
3. 性能：需要性能随着机器数量增加而线性增加

涉及到的概念

* 存储：基本抽象
* 通信：工具视角
* 计算

目标是为应用程序员提供简单的开发接口，就像非分布式的存储、计算架构一样，隐藏具体的实现细节

实现分布式系统使用的工具

* RPC：在不可靠网络中通信，需要利用一种通信协议
* 线程：很多的并发操作
* 并发

### 性能

主要考虑可扩展性性能，这里的可扩展性就是在增加机器之后，得到的性能增长是线性的。因为单机+高级程序员优化程序的成本远大于简单的增加机器。但是这种扩展性不是无限的，在某个位置扩展到一定程度后，会发生性能瓶颈转移，例如从web服务器转移到DB

### 容错

* 可用性：在存在某些故障的情况下整个系统依旧可用
* 可恢复性：某些组件出故障以后，会等待恢复（修复）操作，之后会恢复工作

保证容错能力的方式

* 使用non-volatile storage（非易失性存储）：成本很高，例如固态硬盘。所以要避免过多使用
* replication，保持副本，但是会产生不同步的问题

### 一致性

一致性有很多定义，以一个kv存储服务器为例，它提供两个接口

* `put(k,v)`
* `get(k)`

强一致性会保证`get`总是能得到最近`put`的数据副本，但是在分布式环境中，同一数据可能有多个副本、多个版本，并且由于复制任务的存在，它可能会导致无法保证强一致性

弱一致性没有强一致性的保证，但是它仍然有用，在一些情况下，需要更多的语义限制

为了保证容错性，大部分副本会在物理层面分开存储，那么对于复制（同步）来说通信成本会很高（ms），此时保证强一致性代价很高

### MapReduce

背景是Google需要对大量的网页构建网络索引，进行排序工作。他们设计的这个框架，应用开发人员只需要写Map和Reduce函数，而不关心执行任务的分布式环境

MapReduce程序的输入是分割成64MB数据块的文件

Job：用户编写的Map程序应用到每个小文件（并行），生成`(k,v)`列表，然后所有相同的`k`会被传入Reduce程序，最后返回一个键值对
Task：一个Map程序或一个Reduce程序

输入输出都是文件，存放在GFS中（网络文件系统），和worker进程运行在同一组服务器。在2004年节点上，这套设计的瓶颈在网络吞吐量，每台机器都连接一个交换机，交换机只有一台根交换机，数据吞吐量大概在50MB/m/s，每个Reduce生成的数据因为要保存多个副本，至少会发生一次复制。一次MapReduce被称为Shuffle过程

这个模型的缺点之一是MapReduce模式本身对于一些问题的限制，它是一个批处理系统，而不是流式的

### MapReduce论文记录

MapReduce是一种编程模型，用户指定map函数，处理kv对，生成中间kv对，然后指定reduce函数，将所有相同key的中间值合并起来

程序自动并行，在集群执行，运行时系统关心输入数据的分组，在机器上排布程序，处理机器失败，机器之间的通信

用户指定的map和reduce操作很容易并行化，并且使用重复执行作为容错的主要机制

MapReduce库的用户将计算分为两个函数：Map和Reduce。计算过程接收输入kv对，生成输出kv对。Map接收输入的kv对，生成一些中间过程的kv对。MP库将所有相同中间k（I）的值收集起来，传入Reduce函数。Reduce函数接收I和这个k对应的值。它会合并这些值来构成可能更小集合的值。通常Reduce会生成1个或0个输出值。中间值通过一个迭代器来传入用户的reduce函数，这让我们可以在固定内存中处理很大的数据集

```text
map(String key, String value):
// key: document name
// value: document contents
    for each word w in value:
        EmitIntermediate(w, "1")

reduce(String key, Iterator values):
// key: a word
// value: a list of counts
    int result = 0;
    for each v in values:
        result == ParseInt(v);
    Emit(AsString(result));
```

输入kv和输出kv的类型来自不同的域，中间kv和输出kv的类型来自相同的域

Google的实现：存储使用便宜的IDE磁盘，在每台机器上连接。自己开发的分布式文件系统，使用复制来保证可用性和可靠性。用户提交job到排布系统，每个job包含一些tasks，被scheduler映射到集群中可用的机器上

MapReduce的执行过程

1. MR库将输入文件分为16～64MB的M块，启动集群中的程序
2. 有一个特殊程序--master。剩下的是workers。有M个map任务和R和reduce任务。master选择空闲workers，分配任务
3. 一个被分配任务的worker读取对应的输入块内容。从输入数据转换成kv对传入Map函数，生成的中间kv对保存在内存中
4. 周期性地，缓存的对写入本地磁盘，通过分区函数划分为R个区域。这些缓存对在本地磁盘的位置传给master，它负责将这些位置传给reduce
5. 当reduce的worker被master通知，它使用rpc来读取那些被缓冲的数据。当reduce的worker读取玩后，它会排序这些数据，通过中间k，所有相同k的值会被阻止到一起。这个排序时必要的，因为很多不同的k对应相同的reduce任务。如果中间数据非常大，不能在内存中处理，则需要外部排序
6. reduce的worker会遍历排好序的中间数据，然后对每个唯一的k，将k和对应的中间值集合传入用户的Reduce函数。输出被追加到这个reduce分区的输出文件中
7. 所有的map任务和reduce任务完成后，master唤醒用户程序，此时MapReduce调用会返回用户代码

最后有R和输出文件。通常用户不需要合并这些文件，而是作为另一个MapReduce的输入，或者传入另一个分布式应用，它们可以处理划分为多个文件的输入数据

#### Master数据结构

master需要维护一些数据结构，对每个map和reduce任务，需要保存状态（idle，in-progress，completed）。每个worker机器的id

master是中间文件区域的位置从map任务传到reduce任务的通道。对每个完成的map任务，master保存了R个中间文件区域的大小和位置。接收到这两个信息在map任务完成后更新。这个信息会增量推送给正在完成reduce任务的工作节点

#### Fault Tolerance

##### Worker Failure

master会周期性地ping所有worker，如果一段时间没有收到worker的响应，master会标记此worker为失败，所有该worker上完成的任务都被标记为idle状态，可以被重新排布。任何正在这个worker上运行的任务的状态也会设为idle，可以被重新排布

完成的reduce任务不需要重新执行，因为它们的输出在global file system，而已完成的map任务的输出在本地磁盘。

##### Master Failure

让master将master数据结构周期性地写检查点。如果master死亡，一个新的程序可以从上一个检查点状态继续。然而因为只有一个master，它的失败是不可能的。因此目前实现是如果master失败就丢失任务，由客户端去检查

##### Semantics in the Presence of Failures

用户的map和reduce是输入值的确定函数时，我们的分布式实现会产生和没有问题的顺序执行的程序相同的结果

我们依靠map和reduce任务的原子提交实现这个属性。每个进行中的任务将输出写到私有的临时文件。一个reduce任务有一个这样的文件，一个map任务生成R个这样的文件（一个文件对应一个reduce）。当map任务完成，worker向master发送消息，包含R个临时文件的名称，如果master接收已完成的map任务的信息，会忽视该信息。否则，它会记录R个文件的名称

当reduce任务完成，reduce的worker原子地重命名输出文件为最终的输出文件。如果在多个机器上执行了相同的reduce任务，多个重命名调用会产生一个最终的输出文件。我们利用原子重命名操作（文件系统提供）

最重要的是map和reduce操作符是确定性的，即map和reduce对于同样的输出应该产生同样的结果，这样就会保证MP和顺序执行程序同样的语义，如果map或reduce操作不是确定性的，那么这个系统仍然可以工作，但是不一定会得到顺序执行程序同样的语义，因为对于同一个M的输出，如果R1执行了一遍，在R2执行之前M被重新执行，生成了不一样的结果，此时R2的结果和R1不同，最后的结果文件和顺序执行一遍的结果不同

#### 任务粒度

理想情况下，M会让R应该远大于worker数量，每个worker执行不同的任务，改进动态负载均衡，当worker失败时也会更快恢复：很多完成的map任务会扩散到所有worker机器。通常M更大，因为它处理16MB到64MB的数据。R是worker数量较小的倍数

##### 备份任务

掉队者“straggler”指的是一个MP中最后几个任务非常慢，导致这个问题的原因可能是那台机器硬盘出问题、被分配了更多任务或者一些软件配置导致的。使用备份任务可以在不增加过多资源消耗（百分之几）的前提下提高MP工作的效率。即在只剩最后几个任务的时候，挑一些机器来运行（并列）这些人，无论是原始机器还是备用机器哪个先完成，都认为这个任务已完成

## 线程

线程有自己的程序和地址空间，包含程序计数器、栈和一组寄存器

为什么要使用线程？

1. 处理I/O并发（concurrency）
2. 并行：利用多核计算机
3. 便利性：例如一些希望在后台自动执行的任务（心跳）

使用线程会遇到的挑战

* 竞争（RACE），因为线程是共享内存的，所以容易出现错误，每个线程执行的代码编译的指令不一定是原子的，在利用CPU的时间片执行过程中，可能会得到不期望的结果（例如两个线程同时执行`n+=1`）。使用锁可以解决这个问题
  * 引入锁（go中的Mutex）
  * 线程不共享数据（内存）
* 协同（coordination），多个线程之间需要知道对方的进展，实现协作。Go提供了一些协作工具
  * Channel
  * Cond
  * WaitGroup

（go）内部函数（闭包）引用外部函数的值，在调用时编译器会将这个值从栈移到堆上，这样即使外部函数提前返回，这个值对于内部函数依旧可用，GC会处理一个值的所有引用都实效后的清理工作

（go）运行程序的`--race`模式可以检测程序是否出现竞争情况，这是一种动态分析，即程序必须执行了那段代码才可能发现问题。原理是复制程序的内存（影子内存），对于程序的指令对内存值的修改进行检测
